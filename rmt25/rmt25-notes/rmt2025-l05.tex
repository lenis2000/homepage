\documentclass[letterpaper,11pt,oneside,reqno]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[pdftex,backref=page,colorlinks=true,linkcolor=blue,citecolor=red]{hyperref}
\usepackage[alphabetic,nobysame]{amsrefs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%main packages
\usepackage{amsmath,amssymb,amsthm,amsfonts,mathtools}
\usepackage{graphicx,color}
\usepackage{upgreek}
\usepackage[mathscr]{euscript}

%equations
\allowdisplaybreaks
\numberwithin{equation}{section}

%tikz
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,decorations.markings}

%conveniences
\usepackage{array}
\usepackage{adjustbox}
\usepackage{cleveref}
\usepackage{enumerate}
\usepackage{datetime}

%paper geometry
\usepackage[DIV=12]{typearea}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%draft-specific
\synctex=1
% \usepackage{refcheck,comment}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%this paper specific
\newcommand{\ssp}{\hspace{1pt}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}[proposition]{Lemma}
\newtheorem{corollary}[proposition]{Corollary}
\newtheorem{theorem}[proposition]{Theorem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{definition}
\newtheorem{definition}[proposition]{Definition}
\newtheorem{remark}[proposition]{Remark}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\title{Lectures on Random Matrices
(Spring 2025)
\\Lecture 5: Determinantal Point Processes and the GUE}


\date{Wednesday, February 5, 2025\footnote{\href{https://lpetrov.cc/rmt25/}{\texttt{Course webpage}}
$\bullet$ \href{https://lpetrov.cc/simulations/model/random-matrices/}{\texttt{Live simulations}}
$\bullet$ \href{https://lpetrov.cc/rmt25/rmt25-notes/rmt2025-l05.tex}{\texttt{TeX Source}}
$\bullet$
Updated at \currenttime, \today}}



\author{Leonid Petrov}


\maketitle
\tableofcontents




\section{Recap}
In 
\href{https://lpetrov.cc/rmt25/rmt25-notes/rmt2025-l04.pdf}{Lecture 4}
we discussed global spectral behavior of 
tridiagonal G$\beta$E random matrices,
and obtained the Wigert semicircle law for the eigenvalue density.

In this lecture we shift our focus to another powerful
technique in random matrix theory: the theory of
\emph{determinantal point processes} (DPPs). In the
$\beta=2$ (GUE) case the joint eigenvalue distributions can
be written in determinantal form. We begin by discussing the
discrete version of determinantal processes, and then derive
the correlation kernel for the GUE using orthogonal
polynomial methods. Finally, we show how the
Christoffel--Darboux formula yields a compact representation
of the kernel and indicate how one may represent it as a
double contour integralâ€”an expression well suited for
steepest descent analysis in the large-$n$ limit.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discrete Determinantal Point Processes}
\label{sec:dpp-discrete}
\subsection{Definition and Basic Properties}

Let $\mathfrak{X}$ be a (finite or countably infinite)
discrete set. A \emph{point configuration} on $\mathfrak{X}$
is any subset $X\subset\mathfrak{X}$ (with no repeated
points). A random point process is a probability measure on
the space of such configurations.

\begin{definition}[Determinantal Point Process]
A random point process $P$ on $\mathfrak{X}$ is called \emph{determinantal} if there exists a function (the \emph{correlation kernel}) $K:\mathfrak{X}\times\mathfrak{X}\to\mathbb{C}$ such that for every finite collection of distinct points $x_1,\dots,x_n\in \mathfrak{X}$, the joint probability that these points belong to the random configuration is
\[
\operatorname{\mathbb{P}}\{x_1,\dots,x_n\in X\}=\det\Bigl[K(x_i,x_j)\Bigr]_{i,j=1}^n.
\]
\end{definition}

A standard consequence is that all $k$-point \emph{correlation functions} (or joint intensities) are given by
\[
\rho_k(x_1,\dots,x_k)=\det\Bigl[K(x_i,x_j)\Bigr]_{i,j=1}^k.
\]

Another important property is the \emph{gap probability}. If $I\subset\mathfrak{X}$ is a finite subset, then one may show (see, e.g., \cite{Borodin2009})
\[
\operatorname{\mathbb{P}}\{X\cap I=\varnothing\}=\det\Bigl[I-K_I\Bigr],
\]
where $K_I$ is the restriction of the kernel to $I$. This formula plays a crucial role in describing spacing statistics.

\subsection{Example: One-Dependent Processes}
An interesting application (see \cite{borodin2010adding}) is that any one-dependent point process on a finite segment of $\mathbb{Z}$ is determinantal. (A process is one-dependent if events on sets separated by at least two indices are independent.) This fact illustrates the natural appearance of DPPs in problems with a built-in repulsion between points.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Determinantal Structure in the GUE}
\label{sec:gue-dpp}
\subsection{GUE Joint Density and Orthogonal Polynomials}
Recall that the joint eigenvalue density for the Gaussian Unitary Ensemble (GUE) is given by
\begin{equation}
\label{eq:gue-joint-density}
p(\lambda_1,\dots,\lambda_n)=\frac{1}{Z_{n,2}}\prod_{j=1}^n e^{-\lambda_j^2/2}\prod_{1\le i<j\le n} (\lambda_i-\lambda_j)^2.
\end{equation}
This density, although seemingly complicated, can be rewritten in determinantal form by using the theory of orthogonal polynomials. Namely, if we denote by $\{p_j(x)\}_{j\ge0}$ the family of monic Hermite polynomials orthogonal with respect to the weight
\[
w(x)=e^{-x^2/2},
\]
and define the corresponding orthonormal functions
\[
\psi_j(x)=\frac{1}{\sqrt{h_j}}p_j(x) \sqrt{w(x)},
\]
where $h_j$ are the squared norms, then one obtains the famous determinantal representation for the $k$-point correlation functions:
\begin{equation}
\label{eq:gue-correlation}
\rho_k(x_1,\dots,x_k)=\det\Bigl[K_n(x_i,x_j)\Bigr]_{i,j=1}^k,
\end{equation}
with the correlation kernel
\begin{equation}
\label{eq:gue-kernel-sum}
K_n(x,y)=\sum_{j=0}^{n-1}\psi_j(x)\psi_j(y).
\end{equation}

\subsection{Christoffel--Darboux Formula}
A major advantage of the determinantal representation is that the sum in \eqref{eq:gue-kernel-sum} can be rewritten in closed form using the Christoffel--Darboux formula. In our context, one obtains
\begin{equation}
\label{eq:CD}
K_n(x,y)=\sqrt{w(x)w(y)}\frac{\gamma_{n-1}}{\gamma_n}\frac{p_n(x)p_{n-1}(y)-p_{n-1}(x)p_n(y)}{x-y},
\end{equation}
where $\gamma_n$ denotes the leading coefficient of $p_n(x)$ (for monic polynomials, $\gamma_n=1$ but if one uses an alternate normalization this factor appears).

\begin{remark}
The derivation of the Christoffel--Darboux formula is standard in the theory of orthogonal polynomials; see, e.g., \cite{szego1975orthogonal}. The key idea is that the sum in \eqref{eq:gue-kernel-sum} satisfies a three-term recurrence which then telescopes when writing the difference quotient.
\end{remark}

\subsection{Double Contour Integral Representation and Steepest Descent}
For asymptotic analysis (for example, to derive the sine kernel in the bulk or the Airy kernel at the edge), it is extremely useful to represent the kernel in the form of a double contour integral. One classical route is as follows.

One first expresses the Hermite polynomials via a contour integral representation (see, e.g., the generating function or integral representation for Hermite polynomials):
\[
H_n(z)=\frac{n!}{2\pi i}\oint_\Gamma e^{2zw-w^2}\frac{dw}{w^{n+1}},
\]
with an appropriate choice of contour $\Gamma$. Inserting this representation into the Christoffel--Darboux formula \eqref{eq:CD} and interchanging summation and integration (justified by uniform convergence) one obtains a representation of the kernel as
\begin{equation}
\label{eq:double-contour}
K_n(x,y)=\frac{1}{(2\pi i)^2}\int_{C_1}\int_{C_2} \frac{e^{n\Phi(x,\xi)-n\Phi(y,\eta)}}{\xi-\eta}\,d\xi\,d\eta,
\end{equation}
where $\Phi$ is a certain phase function and the contours $C_1,C_2$ are chosen so that the integrals converge. (The precise form of $\Phi$ depends on the rescaling and normalization.) The representation \eqref{eq:double-contour} is well suited to a steepest descent (saddle point) analysis in the large-$n$ limit, allowing one to derive universal kernels (such as the sine kernel in the bulk)
\[
K_{\mathrm{sine}}(x,y)=\frac{\sin\pi(x-y)}{\pi(x-y)},
\]
or the Airy kernel at the spectral edge.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary and Outlook}
In this lecture we:
\begin{itemize}
  \item Recalled the resolvent (Stieltjes transform) method from Lecture~4 and noted that its analytic completion remains open.
  \item Introduced discrete determinantal point processes and outlined key properties such as the determinantal form of correlation functions and gap probabilities.
  \item Derived (via the orthogonal polynomial method) the determinantal kernel for the GUE, first as a finite sum \eqref{eq:gue-kernel-sum} and then using the Christoffel--Darboux formula \eqref{eq:CD} for a more compact representation.
  \item Indicated how one can represent the kernel as a double contour integral (see \eqref{eq:double-contour}) and how steepest descent techniques are then used to obtain the universal limiting kernels.
\end{itemize}

In subsequent lectures we will use these results to study local eigenvalue statistics (the sine and Airy kernels) and discuss further universality aspects of random matrices.































\appendix
\setcounter{section}{4}

\section{Problems (due DATE)}





\bibliographystyle{alpha}
\bibliography{bib}


\medskip

\textsc{L. Petrov, University of Virginia, Department of Mathematics, 141 Cabell Drive, Kerchof Hall, P.O. Box 400137, Charlottesville, VA 22904, USA}

E-mail: \texttt{lenia.petrov@gmail.com}


\end{document}
